# Frequentist modelling for the analysis of global seabird breeding success
	# Written by David Schoeman (david.schoeman@gmail.com) and Brian Hoover (bhoover@faralloninstitute.org)
		# Input from Bill Sydeman (wsydeman@comcast.net) and Sarah-Ann Thompson (sathompson@faralloninstitute.org)
			# June 2020 - March 2021

# Depends on data generated by 1_Data_Prep.R

# Source the functions ---------------------------------------------------------

	source("0_Seabird_Helpers.R")

# Make the saved data available ------------------------------------------------

	dat <- readRDS("Data/dat.rda")


# Some initial inspection of available sample sizes ----------------------------

	dat %>% 
		group_by(Hemisphere,TL,Depth) %>% 
		summarise(n = n_distinct(sppsite)) %>% 
		pivot_wider(names_from = Depth, values_from = n) %>% 
	data.frame()
	# There IS replication in each hem x TL x depth interaction cell, but more in some than others
	# Insufficient replication to allow four-way interactions, so limit to three-way interactions

	
# Model of standardised breeding success ---------------------------------------

	f.sbs <- lme(stbs ~ yearno + Hemisphere + TL + Depth +
							 yearno:Hemisphere + yearno:TL + yearno:Depth + Hemisphere:TL + Hemisphere:Depth + TL:Depth +
							 yearno:Hemisphere:TL + yearno:Hemisphere:Depth + yearno:TL:Depth,
							 random = ~yearno|sppsite, # Allow random slopes by time series
							 correlation = corCAR1(form = ~ yearno|sppsite), # Incorporate temporal autocorrelation in discontinuous time series, by time series
							 control = list(maxIter = 10000, niterEM = 10000), # Give it time to converge
							 method = "ML",
							 data = dat)
	summary(f.sbs) # Brief inspection of coefficients
	Anova(f.sbs) # General significance of terms

	# Simplify the model - use Log-likelihood ration test backed up by AIC
	# Results are in Table S4
		drop1(f.sbs, test = "Chi") # For Table S4
		 f.sbs1 <- update(f.sbs, ~. -yearno:TL:Depth) # Drop the non-significant interaction with least explanatory power (according to AIC)
		drop1(f.sbs1, test = "Chi")
		 f.sbs2 <- update(f.sbs1, ~. -TL:Depth) # Drop the non-significant interaction with least explanatory power (according to AIC)
		drop1(f.sbs2, test = "Chi")
		 f.sbs3 <- update(f.sbs2, ~. -yearno:Hemisphere:Depth) # Drop the non-significant interaction with least explanatory power (according to AIC)
		drop1(f.sbs3, test = "Chi")
		 f.sbs4 <- update(f.sbs3, ~. -Hemisphere:Depth) # Drop the non-significant interaction with least explanatory power (according to AIC)
		drop1(f.sbs4, test = "Chi")
			f.sbs5 <- update(f.sbs4, ~. -yearno:Depth) # Drop the non-significant interaction with least explanatory power (according to AIC)
		drop1(f.sbs5, test = "Chi") 
			f.sbs6 <- update(f.sbs5, ~. -Depth) # Drop the non-significant term with least explanatory power (according to AIC)
		drop1(f.sbs6, test = "Chi") # The three-way interaction is significant, so keep all subsidiary interactions and effects
		Anova(f.sbs6) # Remaining model terms, Table S4
		f.sbs.fin <- update(f.sbs6, ~., method = "REML") # Update to REML to extract estimates
		summary(f.sbs.fin)
		Store(f.sbs.fin) # Write to cache so we don't lose it
	
	# Model diagnostics (as per: https://rpubs.com/bbolker/glmmchapter)
		grid.arrange(plot(f.sbs.fin, type = c("p", "smooth")),
								 plot(f.sbs.fin, sqrt(abs(resid(.))) ~ fitted(.),
								 		 type = c("p","smooth"), ylab = expression(sqrt(abs(resid)))),
								 plot(f.sbs.fin, resid(., type = "pearson") ~ yearno,
								 		 type = c("p","smooth")),
								 qqnorm(f.sbs.fin, abline = c(0, 1),
								 )) # Looks pretty good!
		
	# Plots of standardised breeding success	
		ff1 <- pltmm(f.sbs.fin, dat)
		
		# Setting color palette and pull specific Viridis shades
		pal <- viridis(4) #separate into 4 discrete values
		maps <- tibble(labels = c("North","South"),
		               colors = case_when(labels == "North" ~ pal[1],
		                                  labels == "South" ~ pal[3]))
		values <- set_names(maps$colors, maps$labels)
		
		ggplot() + 
		  geom_smooth(data = dat, aes(x = yearno + min(year), y = stbs, group = sppsite, colour = Hemisphere),
		              method = "lm", se = FALSE,linetype="dashed",
		              lwd = .1) +
		  geom_line(data = ff1, aes(x = yearno + min(dat$year), y = y, colour = Hemisphere)) +
		  geom_ribbon(data = ff1, aes(x = yearno + min(dat$year), ymin = se.lw, ymax = se.hi, fill = Hemisphere), alpha = 0.45) +
		  theme_bw() +
		  theme(axis.text = element_text(size = 10,family="Helvetica"), # Make the axis tick labels font a little larger
		        axis.title = element_text(size = 12,family="Helvetica"),
		        axis.title.x = element_text(vjust = -2,family="Helvetica",size=12),
		        axis.title.y = element_text(vjust = 2,family="Helvetica",size=12),
		        panel.grid.major = element_blank(),
		        panel.grid.minor = element_blank(),
		        legend.position="top",
		        legend.text=element_text(size=10,family="Helvetica"),
		        legend.title=element_text(size=10,family="Helvetica"))+
		  labs(x = "Year", 
		       y = "Normalized breeding productivity \n (± standard error)") +
		  scale_fill_manual(values=values)+
		  scale_color_manual(values=values)+
		  facet_grid(cols = vars(TL))
		ggsave("Figs/Fig2a.pdf", height = 9, width = 12)
		


# Probability of breeding failure ----------------------------------------------
	
	# Use glmmPQL so that I can adjust for autocorrelation
		f.bf <- glmmPQL(pr_failure ~ yearno + Hemisphere + TL + Depth +
											yearno:Hemisphere + yearno:TL + yearno:Depth + Hemisphere:TL + Hemisphere:Depth + TL:Depth +
											yearno:Hemisphere:TL + yearno:Hemisphere:Depth + yearno:TL:Depth,
										 	random = ~yearno|sppsite,
										 	correlation = corCAR1(form = ~ yearno|sppsite), 
										 	data = dat,
										 	family = binomial) # OK, can extract estimates, it seems
		summary(f.bf) # Initial view of coefficients
		# Simplify the model - here, we have only the p-values in the summary to work with
		f.bf1 <- update(f.bf, ~. -yearno:Hemisphere:Depth) # p = 0.7713
			summary(f.bf1)
		f.bf2 <- update(f.bf1, ~. -Hemisphere:Depth) # p = 0.7012
			summary(f.bf2) # All remaining terms/interactions are significant or part of higher-order interactions
		f.bf.fin <- f.bf2
		Store(f.bf.fin) # Write to cache so we don't lose it
			# Note that even Ben Bolker cannot find a way to compute AIC or qAIC from glmmPQ: models...see https://cran.r-project.org/web/packages/bbmle/vignettes/quasi.pdf
	# Model diagnostics aren't useful for binary binomial GLMMs, so we don't explore them here
	
	# # Plots of probability of breeding failure
		ff <- pltmm(f.bf.fin, dat)
		ggplot(data = dat, aes(x = yearno + min(dat$year), y = pr_failure, group = sppsite)) +
		  geom_point(data = dat,
		             aes(x = yearno + min(year), y = pr_failure, group=sppsite, colour = Hemisphere),
		             alpha = .15) +
		  # geom_smooth(aes(colour = Hemisphere),     # uncomment to include binomially modeled individual smoothed times series
		  #              method = "glm", method.args = list(family = "binomial"),
		  #             se = FALSE,
		  #              size = .1, alpha = 0.025) +
		  geom_ribbon(data = ff, aes(x = yearno + min(dat$year), ymin = se.lw, ymax = se.hi, fill = Hemisphere), alpha = 0.45, inherit.aes = FALSE) +
		  geom_line(data = ff, aes(x = yearno + min(dat$year), y = y, colour = Hemisphere), inherit.aes = FALSE) +
		  labs(x = "Year", 
		       y = "Probability of breeding failure \n  (± standard error)") +
		  theme_bw() +
		  theme(
		    axis.text = element_text(size = 10,family="Helvetica"), 
		    axis.title = element_text(size = 10,family="Helvetica"),
		    axis.title.x = element_text(vjust = -2,family="Helvetica",size=12),
		    axis.title.y = element_text(vjust = 2,family="Helvetica",size=12), 
		    panel.grid.major = element_blank(),
		    panel.grid.minor = element_blank(),
		    legend.position="top",
		    legend.text=element_text(size=10,family="Helvetica"),
		    legend.title=element_text(size=10,family="Helvetica"))+
		  scale_fill_manual(values=values)+
		  scale_color_manual(values=values)+
		  facet_grid(cols = vars(TL), rows = vars(Depth))
		ggsave("Figs/Fig2b.pdf", height = 9, width = 12)
		
		

# Point estimates for std breeding success for inclusion in the text -----------
	
	sbs.ests <- ff1 %>% 
		group_by(Hemisphere, TL) %>% 
		filter(row_number()==1 | row_number()==n()) %>%
		mutate(seU = round(se.hi - y, 2),
					 seL = round(y - se.lw,2),
					 y = round(y, 2)) %>% 
		dplyr::select(yearno, Hemisphere, y, seU, seL)


# Sensitivity tests Hemisphere vs RoW ------------------------------------------

	# Load RoW, vocc and xy data
		RoW <- stack("Data/RoW.grd")
		vocc <- stack("Data/vocc.grd")
		xy <- readRDS("Data/xy.rda")
	
	# Fit full model, less Hemisphere - then simplify
		s.sbs <- lme(stbs ~ yearno + TL + Depth +
						 yearno:TL + yearno:Depth + TL:Depth +
						 yearno:TL:Depth,
						 random = ~yearno|sppsite, # Allow random slopes by time series
						 correlation = corCAR1(form = ~ yearno|sppsite), # Incorporate temporal autocorrelation in discontinuous time series, by time series
						 control = list(maxIter = 10000, niterEM = 10000), # Give it time to converge
						 method = "ML",
						 data = dat)
			drop1(s.sbs, test = "Chi")
				s.sbs1 <- update(s.sbs, ~. -yearno:TL:Depth)
			drop1(s.sbs1, test = "Chi")	
				s.sbs2 <- update(s.sbs1, ~. -TL:Depth)
			drop1(s.sbs2, test = "Chi")
				s.sbs3 <- update(s.sbs2, ~. -yearno:Depth)
			drop1(s.sbs3, test = "Chi")
				s.sbs4 <- update(s.sbs3, ~. -Depth)
			drop1(s.sbs4, test = "Chi")
			summary(s.sbs4) # Significant temporal trends by TL, after we exclude Hemsiphere from the model
		s.sbs.fin <- update(s.sbs4, method = "REML")
		
		# Set up the random effects for modelling
			f.re <- ranef(s.sbs.fin) %>%  # Random effects from the bs model
				as.data.frame() %>% 
				rename(Intercept = "(Intercept)", tsSlope = yearno) %>% # Rename the variables 
				mutate(sppsite = row.names(ranef(s.sbs.fin))) # Add the sppsite back in
			f.re <- left_join(f.re, xy) # Merge with xy to get depth, TL, etc.
			b <- 300000 # radius of aggregation, in m (i.e., 300 km)
			f.re$vocc <- unlist(raster::extract(vocc[[1]], dplyr::select(f.re, x, y), buffer = b, fun = mean, na.rm = TRUE)) # Mean VoCC per site within a 300-km radius
			f.re$RoW <- unlist(raster::extract(RoW[[1]], dplyr::select(f.re, x, y), buffer = b, fun = mean, na.rm = TRUE)) # Mean RoW per site within a 300-km radius
			# Check correlation beween RoW and vocc
				cor.check <-f.re %>% 
					distinct(x, y, .keep_all = TRUE) %>% 
					dplyr::select(site, x, y, vocc, RoW) %>% 
					arrange(site)
				with(cor.check, cor.test(RoW, vocc)) # Correlation test of VoCC vs RoW
				ggplot(f.re, aes(x = RoW, y = vocc)) +
					geom_point() +
					geom_smooth(method = lm, se = FALSE) # Corresponding plot
			
		# Linear models for random effects
			frem1 <- lm(tsSlope ~ vocc, weights = nyear, data = f.re)
			anova(frem1) # vocc is a significant explanatory variable for the random slopes
			summary(frem1)
			frem2 <- lm(tsSlope ~ RoW, weights = nyear, data = f.re)
			anova(frem2) # RoW is a significant explanatory variable for the random slopes
			summary(frem2)
			# Significant effect on random effects of both RoW or VoCC
	
# Goto 3_Hemispheric_Assymmetry
	
	
	
